<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Divulgação Científica: Ética em IA</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <h1>Divulgação Científica sobre Ética em IA</h1>
        <p style="text-align: justify;">A naturalização do uso de tecnologias digitais no cotidiano — como reconhecimento facial, assistentes virtuais e aplicativos de saúde — tem mascarado práticas que comprometem direitos fundamentais. A promessa de praticidade e eficiência frequentemente se sobrepõe a discussões essenciais sobre privacidade, consentimento e justiça. O uso dessas ferramentas, sem regulamentação adequada, tem aprofundado desigualdades estruturais já presentes na sociedade. Como aponta Safiya Noble (2018), os algoritmos não são neutros: refletem e reproduzem os vieses e preconceitos de seus desenvolvedores e das bases de dados utilizadas, muitas vezes invisibilizando grupos historicamente marginalizados.</p>
        <img src="imgIA.png" alt="Imagem ilustrativa" class="promo-img">
        <p style="text-align: justify;">Diversos estudos já demonstraram que tecnologias de reconhecimento facial, por exemplo, apresentam taxas de erro significativamente maiores ao lidar com rostos de pessoas negras e mulheres (Buolamwini & Gebru, 2018). Essas falhas não são apenas técnicas — são políticas, pois colocam em risco a integridade física e moral de certos grupos. Além disso, há uma crescente opacidade quanto ao armazenamento e uso dos dados coletados, especialmente por empresas privadas que atuam no espaço urbano sob justificativas de segurança. Essa dinâmica evidencia a urgência de uma governança algorítmica baseada na transparência, no controle social e no direito ao não monitoramento.</p>
        <p style="text-align: justify;">O avanço da inteligência artificial precisa ser acompanhado por um debate público qualificado, que considere seus impactos sociais e éticos. A ausência de regulação permite que o chamado "solucionismo tecnológico" imponha soluções digitais para problemas complexos sem participação cidadã efetiva (Morozov, 2013). Para garantir que os avanços tecnológicos promovam inclusão em vez de exclusão, é fundamental envolver áreas como filosofia, antropologia e sociologia na construção de políticas públicas e no desenho de sistemas digitais. Apenas uma abordagem inter e transdisciplinar será capaz de equilibrar inovação com justiça social.</p>
        <h3>Referências</h3>
        <ul>
        <li style="text-align: justify;">Noble, S. U. (2018). <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em>. NYU Press.</li>
        <li style="text-align: justify;">Buolamwini, J., & Gebru, T. (2018). <em>Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</em>. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency.</li>
        <li style="text-align: justify;">Morozov, E. (2013). <em>To Save Everything, Click Here: The Folly of Technological Solutionism</em>. PublicAffairs.</li>
        </ul>

        <p><a href="index.html" id="divulgacao-link">Voltar ao jogo</a></p>
    </div>
</body>
</html>
